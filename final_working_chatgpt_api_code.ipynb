{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RE3Ss1RsroaB",
        "outputId": "406f563f-1ed0-4033-cdce-232012f919e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai gradio pillow requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT API - Code working**"
      ],
      "metadata": {
        "id": "O0qqbgDUshzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade openai gradio pillow requests\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import openai\n",
        "\n",
        "# -----------------------------\n",
        "# Set your OpenAI API key here\n",
        "# -----------------------------\n",
        "\n",
        "openai.api_key = \"changedapikeysk-proj-apic4Q8vsmRmbEEf4HofpZ-Vv_7o1GF1e4ESHvlF7fFuaWGTWJJjXXDMd7DR65iVgwa1jLVcUpVtbT3BlbkFJxq2DXrixjDkUtAap_b2Vbz0AdabMM2WEhbcLslyVIh9jcamEoQLXsKhkoldDVJNS_2xGs07UQA\"  # <-- replace with your real key\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Global chat history\n",
        "# -----------------------------\n",
        "chat_history = []\n",
        "\n"
      ],
      "metadata": {
        "id": "E6GkgzvmxfdQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade openai gradio pillow requests\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import openai\n",
        "\n",
        "# -----------------------------\n",
        "# OpenAI API Key\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Global chat history\n",
        "# -----------------------------\n",
        "chat_history = []\n",
        "\n",
        "# -----------------------------\n",
        "# Preview image from URL\n",
        "# -----------------------------\n",
        "def preview_image(image_url):\n",
        "    try:\n",
        "        img_data = requests.get(image_url).content\n",
        "        pil_img = Image.open(BytesIO(img_data))\n",
        "        return pil_img\n",
        "    except Exception as e:\n",
        "        print(f\"[DEBUG] Could not load image: {e}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Ask GPT-4o about image\n",
        "# -----------------------------\n",
        "def ask_medical_image(image_url, user_input):\n",
        "    global chat_history\n",
        "\n",
        "    if not user_input:\n",
        "        return \"\", []\n",
        "\n",
        "    # Append user message\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Construct messages for OpenAI API\n",
        "    messages = chat_history.copy()\n",
        "    if image_url:\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"[Image URL: {image_url}] Please consider this image while answering.\"\n",
        "        })\n",
        "\n",
        "    # Call OpenAI Chat API (>=1.0)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    assistant_msg = response.choices[0].message.content\n",
        "\n",
        "    # Append assistant response\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "\n",
        "    # Format for Gradio Chatbot (list of dicts with role/content)\n",
        "    return assistant_msg, chat_history\n",
        "\n",
        "# -----------------------------\n",
        "# Summarize conversation\n",
        "# -----------------------------\n",
        "def summarize_conversation():\n",
        "    global chat_history\n",
        "    if not chat_history:\n",
        "        return \"No conversation to summarize.\"\n",
        "\n",
        "    summary_prompt = \"Summarize the following conversation medically and concisely:\\n\"\n",
        "    for msg in chat_history:\n",
        "        summary_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "        max_tokens=300,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# -----------------------------\n",
        "# Diagnostic / treatment suggestions\n",
        "# -----------------------------\n",
        "def diagnostic_suggestions():\n",
        "    global chat_history\n",
        "    if not chat_history:\n",
        "        return \"No conversation for diagnostics.\"\n",
        "\n",
        "    diag_prompt = \"Based on the following conversation, provide possible diagnostic or treatment suggestions:\\n\"\n",
        "    for msg in chat_history:\n",
        "        diag_prompt += f\"{msg['role']}: {msg['content']}\\n\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": diag_prompt}],\n",
        "        max_tokens=400,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# -----------------------------\n",
        "# Clear chat\n",
        "# -----------------------------\n",
        "def clear_chat():\n",
        "    global chat_history\n",
        "    chat_history = []\n",
        "    return \"\", None, [], \"\", \"\"\n"
      ],
      "metadata": {
        "id": "PpHhO3F9zjW3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Gradio UI\n",
        "# -----------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Medical Assistant with ChatGPT (GPT-4o): Image + Chat + Summary + Diagnostics\")\n",
        "\n",
        "    with gr.Row():\n",
        "        img_url_input = gr.Textbox(label=\"Image URL\", placeholder=\"Paste any public medical image URL\")\n",
        "        preview_img = gr.Image(label=\"Image Preview\")\n",
        "    img_url_input.change(fn=preview_image, inputs=img_url_input, outputs=preview_img)\n",
        "\n",
        "    question_input = gr.Textbox(label=\"Ask a question about the image\", placeholder=\"Example: What abnormalities are present in this X-ray?\")\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"Ask\")\n",
        "        clear_btn = gr.Button(\"Clear Chat\")\n",
        "        summary_btn = gr.Button(\"Summarize Conversation\")\n",
        "        diag_btn = gr.Button(\"Diagnostic / Treatment Suggestions\")\n",
        "\n",
        "    chat_output = gr.Chatbot(label=\"Conversation\")\n",
        "    answer_output = gr.Textbox(label=None, lines=10, placeholder=\"GPT-4o answer will appear here...\")\n",
        "\n",
        "    summary_output = gr.Textbox(label=\"Summary\", lines=8, placeholder=\"Summary will appear here...\")\n",
        "    diag_output = gr.Textbox(label=\"Diagnostics / Treatment Suggestions\", lines=12, placeholder=\"Diagnostics will appear here...\")\n",
        "\n",
        "    # Button actions\n",
        "    submit_btn.click(\n",
        "        fn=ask_medical_image,\n",
        "        inputs=[img_url_input, question_input],\n",
        "        outputs=[answer_output, chat_output]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_chat,\n",
        "        inputs=None,\n",
        "        outputs=[answer_output, preview_img, chat_output, summary_output, diag_output]\n",
        "    )\n",
        "\n",
        "    summary_btn.click(\n",
        "        fn=summarize_conversation,\n",
        "        inputs=None,\n",
        "        outputs=summary_output\n",
        "    )\n",
        "\n",
        "    diag_btn.click(\n",
        "        fn=diagnostic_suggestions,\n",
        "        inputs=None,\n",
        "        outputs=diag_output\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "5uwkfjKnxfix",
        "outputId": "99cf1e1e-0380-4223-d60b-9c0719baa603"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5c7b030ebf1fecfedf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5c7b030ebf1fecfedf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://5c7b030ebf1fecfedf.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fv2FtsHIxfmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6o-eGmaJxfnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mkj8WrWhxfrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pMg1kbm4xfsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
